{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = keras.models.load_model('./fight_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(\"./No_Fight/fno_fight1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the width and height of the video\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a background subtractor object\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a kernel for morphological operations\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the bounding boxes of the detected fights\n",
    "fight_boxes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start the video capture loop\n",
    "while True:\n",
    "\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is None\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(gray)\n",
    "\n",
    "    # Perform morphological operations to remove noise\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find the contours in the foreground mask\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate over the contours\n",
    "    for contour in contours:\n",
    "\n",
    "        # Get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Check if the bounding box is large enough\n",
    "        if w > 50 and h > 50:\n",
    "\n",
    "            # Add the bounding box to the list of fight boxes\n",
    "            fight_boxes.append([x, y, w, h])\n",
    "\n",
    "    # Predict the class of each bounding box\n",
    "    fight_predictions = model.predict(np.array([cv2.resize(frame[y:y + h, x:x + w], (32, 32)) for x, y, w, h in fight_boxes]))\n",
    "\n",
    "    # print(fight_predictions)\n",
    "    # Iterate over the predictions\n",
    "    for i, prediction in enumerate(fight_predictions):\n",
    "\n",
    "        # Get the class label\n",
    "        class_label = np.argmax(prediction)\n",
    "\n",
    "        # Check if the class label is fight\n",
    "        if class_label == 1:\n",
    "\n",
    "            # Draw a red rectangle around the bounding box\n",
    "            cv2.rectangle(frame, (fight_boxes[i][0], fight_boxes[i][1]), (fight_boxes[i][0] + fight_boxes[i][2], fight_boxes[i][1] + fight_boxes[i][3]), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Check if the user wants to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
